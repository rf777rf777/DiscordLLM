import os
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
from core.config import Settings
from openai import OpenAI
import json
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
import torch

# è¨­å®š OpenAI API é‡‘é‘°
openAI_apikey = Settings.OPENAPIKEY
img_prompt_type = "è‹±æ–‡ Stable Diffusion" #"è‹±æ–‡"
model_name = "Anything-v3-0-better-vae"

def create_chat_function_call(client: OpenAI, prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©æ‰‹ï¼Œç”¨ Function Calling æ–¹å¼åˆ¤æ–·ä½¿ç”¨è€…æ˜¯å¦æƒ³ç”Ÿæˆåœ–ç‰‡ã€æè¿°åœ–ç‰‡æˆ–é¢¨æ ¼è½‰æ›ã€‚"},
            {"role": "user", "content": prompt}
        ],
        functions=[
            {
                "name": "create_image",
                "description": "æ ¹æ“šæç¤ºè©ç”¢ç”Ÿåœ–ç‰‡",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {"type": "string", "description": f"æ­£å‘æç¤ºè©ï¼Œå¾åŸæœ¬çš„è¼¸å…¥promptä¸­æ‰¾å‡ºä½¿ç”¨è€…æƒ³è¦çš„å…ƒç´ ï¼Œåšæˆ{img_prompt_type} promptï¼Œä½¿ç”¨é€—é»åˆ†éš”ï¼Œä¸¦ç›¡å¯èƒ½è£œè¶³ç´°ç¯€èˆ‡èƒŒæ™¯å…ƒç´ ï¼Œè½‰æ›æˆ Stable Diffusion æ­£å‘æç¤ºè©ã€‚"},
                        "negative": {"type": "string", "description": f"è² å‘æç¤ºè©ï¼Œå¾åŸæœ¬çš„promptä¸­æ‰¾å‡ºä½¿ç”¨è€…ä¸æƒ³è¦çš„å…ƒç´ ï¼Œä¸€æ¨£æ˜¯{img_prompt_type} promptï¼Œè‹¥æ²’æœ‰å‰‡ç‚ºç©ºå­—ä¸²ï¼Œæœ€å¾Œè½‰æ›æˆ Stable Diffusion è² å‘æç¤ºè©ã€‚"},
                        "style": {"type": "array", "items": {"type": "string"}, "description": "åœ–ç‰‡é¢¨æ ¼ï¼Œå¯è¤‡é¸ï¼Œé¸é …å¦‚ä¸‹: realisticã€animeã€illustrationã€pixel_artã€cyberpunkã€japaneseã€fantasyã€steampunk"}
                    },
                    "required": ["prompt"]
                }
            },
            {
                "name": "describe_image",
                "description": "ç”¨è‡ªç„¶èªè¨€æè¿°åœ–ç‰‡ä¸­çš„å…§å®¹",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "image_path": {"type": "string", "description": "åœ–ç‰‡æª”æ¡ˆè·¯å¾‘"}
                    },
                    "required": ["image_path"]
                }
            },
            {
                "name": "stylize_image",
                "description": "å°‡åœ–ç‰‡è½‰æ›ç‚ºç‰¹å®šé¢¨æ ¼ï¼ˆå¦‚æ‰‹ç¹ªã€æ’ç•«ç­‰ï¼‰",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "image_path": {"type": "string", "description": "åœ–ç‰‡æª”æ¡ˆè·¯å¾‘"},
                        "style": {"type": "array", "items": {"type": "string"}, "description": "è¦å¥—ç”¨çš„é¢¨æ ¼ï¼Œå¦‚ animeã€illustrationï¼Œå¯è¤‡é¸"}
                    },
                    "required": ["image_path", "style"]
                }
            },
            {
                "name": "chat",
                "description": "ä¸€èˆ¬å°è©±ï¼Œéåœ–åƒç”Ÿæˆ",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "string"}
                    },
                    "required": ["content"]
                }
            }
        ],
        function_call="auto",
        temperature=1.2
    )

    choice = response.choices[0]
    if choice.finish_reason == "function_call":
        func_call = choice.message.function_call
        name = func_call.name
        args = json.loads(func_call.arguments)
        return {"function": name, "args": args}
    else:
        return {"function": "chat", "args": {"content": choice.message.content.strip()}}


def create_chat(client: OpenAI, prompt):
    # è¨­è¨ˆæç¤ºè©
    sys_prompt = f'''
    ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©æ‰‹ï¼Œè«‹åˆ¤æ–·ä»¥ä¸‹ä½¿ç”¨è€…è¼¸å…¥çš„æ„åœ–ï¼Œä¸¦ä»¥ JSON æ ¼å¼å›æ‡‰ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
    {{
      "intent": "<æ„åœ–é¡å‹>",
      "content": "<å›æ‡‰å…§å®¹>",
      "negative-content": "<è² å‘å›æ‡‰å…§å®¹>",
      "style": "<åœ–ç‰‡é¢¨æ ¼>"
    }}
    æ„åœ–é¡å‹å¯ä»¥æ˜¯ï¼š
    - "image"ï¼šå¦‚æœä½¿ç”¨è€…è¦æ±‚ç”Ÿæˆåœ–ç‰‡ï¼Œæ­¤æ™‚çš„ <å›æ‡‰å…§å®¹> å¿…é ˆæ˜¯è©³ç´°ã€è±å¯Œä¸”å…·é«”çš„{img_prompt_type} promptï¼Œæ¨¡å‹ä½¿ç”¨ï¼š{model_name}ã€‚è«‹ç›¡å¯èƒ½å…·è±¡åŒ–å…§å®¹ã€è£œè¶³ç´°ç¯€èˆ‡èƒŒæ™¯ã€‚ <è² å‘å›æ‡‰å…§å®¹> æ‡‰ç‚ºä½¿ç”¨è€…æ•˜è¿°ä¸æƒ³è¦çš„éƒ¨åˆ†ï¼Œä¸€æ¨£æ˜¯{img_prompt_type} promptï¼Œè‹¥æ²’æœ‰å‰‡ä¸€æ¨£ç‚ºç©ºå­—ä¸²ã€‚
    - "chat"ï¼šå¦‚æœä½¿ç”¨è€…é€²è¡Œä¸€èˆ¬å°è©±ï¼Œå°‡å›æ‡‰å¯«åœ¨ <å›æ‡‰å…§å®¹> ï¼Œä¸¦ä¸” <è² å‘å›æ‡‰å…§å®¹> ä¿æŒç‚ºç©ºå­—ä¸²ã€‚    
    åœ–ç‰‡é¢¨æ ¼å¯ä»¥æ˜¯ï¼š
    - "realistic"
    - "anime"
    - "illustration"
    - "pixel_art"
    - "cyberpunk"
    - "japanese"
    - "fantasy"
    - "steampunk"
    - "":è‹¥ä½¿ç”¨è€…é€²è¡Œä¸€èˆ¬å°è©±ï¼Œæˆ–ç„¡æ³•åˆ¤æ–·ç‚ºä½•ç¨®åœ–ç‰‡é¢¨æ ¼æ™‚ï¼Œä¿æŒç©ºå­—ä¸²ã€‚
    ä»¥ä¸Šåœ–ç‰‡é¢¨æ ¼å¯ä»¥è¤‡é¸ï¼Œä½¿ç”¨é€—é»åˆ†éš”ã€‚
    
    è«‹åƒ…å›å‚³ JSONï¼Œç„¡éœ€å…¶ä»–èªªæ˜ã€‚
    '''

    response = client.chat.completions.create(
        model="gpt-3.5-turbo", 
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": prompt}],
        temperature=1
    )

    # è§£æå›æ‡‰
    response_text = response.choices[0].message.content.strip()
    try:
        response_json = json.loads(response_text)
        return response_json
    except json.JSONDecodeError:
        return {"intent": "error", "content": "ç„¡æ³•è§£æçš„å›æ‡‰"}

def create_dall_e_image(client: OpenAI, prompt):
    response = client.images.generate(
        model="dall-e-2",
        prompt=prompt,
        size="1024x1024",
        quality="standard",
        n=1,
    )
    return response.data[0].url

def create_sd_image(pos_prompt, neg_prompt, style):
    pipe = StableDiffusionPipeline.from_pretrained("src/Anything-v3-0-better-vae", torch_dtype=torch.float32, safety_checker=None)  # âœ… ç¦ç”¨ safety checker
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

    pipe = pipe.to("mps")
    
    pipe.load_textual_inversion("src/temp/easynegative.safetensors", token="easynegative", mean_resizing=False)
    pipe.load_textual_inversion("src/temp/badhandv4.pt", token="badhandv4", mean_resizing=False)

    pipe.enable_attention_slicing()
    style_prompt = get_style_prompt(style)
    
    positive_prompt = f"masterpiece, best quality, (white stocking), {style_prompt}, {pos_prompt}"
    negative_prompt = f"easynegative, (badhandv4), lowres, bad anatomy, worst quality, blurry, extra hands, ugly, watermark, {neg_prompt}"
    #è¨­å®šéš¨æ©Ÿç¨®å­
    #generator = torch.manual_seed(42)

    image = pipe(
        prompt=positive_prompt,
        negative_prompt=negative_prompt,
        num_inference_steps=30,
        guidance_scale=6.5,
        #generator=generator,
        height=512,
        width=512
    ).images[0]

    image.save("result_test1.png")

def get_style_prompt(style_str):
    if not style_str:
        return ""
    
    style_prompt_dict = {
        "realistic": "realistic, photorealistic, ultra detailed",
        "anime": "anime, anime style, 2d, vibrant colors",
        "illustration": "illustration, concept art, soft shading",
        "pixel_art": "pixel art, 8-bit, retro game style",
        "cyberpunk": "cyberpunk, neon lights, futuristic, sci-fi",
        "japanese": "japanese style, kimono, sakura, ukiyo-e",
        "fantasy": "fantasy, magical, epic lighting, ethereal glow",
        "steampunk": "steampunk, brass gears, goggles, Victorian era"
    }    
    #styles = [s.strip() for s in style_str.split(",")]
    styles = [s.strip() for s in style_str]

    prompts = [style_prompt_dict[s] for s in styles if s in style_prompt_dict]
    return ", ".join(prompts)

def describe_image(text):
    print(text)
    
def stylize_image(text1, text2):
    print(text1)
    print(text2)

def chat_type1():
    result = create_chat(client, user_prompt)
    print(result)

    if result["intent"] == "image":
        #await message.channel.send(f"æ­£åœ¨ç‚ºä½ ç”Ÿæˆåœ–ç‰‡ï¼š`{content}`")
        try:
            # img_url = create_dall_e_image(client, result["content"])
            create_sd_image(result["prompt"], result["negative"], result["style"])
        except Exception as e:
            print(e)
            #await message.channel.send(f"ç”Ÿæˆåœ–ç‰‡æ™‚å‡ºéŒ¯ï¼š{str(e)}")
    else:
        print(result["content"])  

def chat_type2():
    result = create_chat_function_call(client, user_prompt)
    args = result["args"]
    if result["function"] == "create_image":
        create_sd_image(args["prompt"], args.get("negative", ""), args.get("style", []))
    elif result["function"] == "describe_image":
        describe_image(args["image_path"])
    elif result["function"] == "stylize_image":
        stylize_image(args["image_path"], args.get("style", []))
    else:
        print("ğŸ’¬", args.get("content", "ç„¡æ³•å›æ‡‰"))

client = OpenAI(api_key=openAI_apikey)

#url = create_image(client, "A cute cartoon-style cat on Mars drinking bubble tea, in the art style of The Powerpuff Girls. The cat has large expressive eyes, a small round body, and floats slightly above the red rocky Martian surface with a space-themed background. The bubble tea cup is oversized with a straw, and there are craters and distant stars in the scene. The overall aesthetic is bright, colorful, and bold, with clean lines and minimal shading, closely mimicking the style of The Powerpuff Girls animation.")
#print(url)

user_prompt = "æˆ‘æƒ³ç•«æ—¥å¼å¥‡å¹»é¢¨èƒŒæ™¯ï¼Œä¸è¦éƒ½å¸‚é¢¨ã€ä¸æƒ³è¦é«˜æ¨“å»ºç¯‰ï¼Œä¹Ÿä¸è¦å¤ªç¾ä»£çš„é¢¨æ ¼"
#user_prompt = "ä»€éº¼æ˜¯å¤§å‹èªè¨€æ¨¡å‹"
user_prompt = '''
äºŒæ¬¡å…ƒé¢¨æ ¼æ’ç•«ï¼Œä¸€ä½ç©¿è‘—è¯éº—ä¸­å¼æ”¹è‰¯æœé£¾çš„å¹´è¼•å¥³æ€§è§’è‰²ã€‚å¥¹å…·æœ‰ä»¥ä¸‹ç‰¹å¾µï¼š

    - é«®å‹èˆ‡é«®è‰²ï¼šé•·é«®å‘ˆæ·±ç´«è‰²æˆ–æ¥è¿‘é»‘è‰²ï¼Œé«®å°¾ç•¥å¸¶äº›å¾®ç²‰ç´«è‰²æ¼¸å±¤ã€‚é«®å‹ç•¥é¡¯æ³¢æµªï¼ŒæŸ”é †åœ°å‚è‡³èº«é«”å…©å´ã€‚

    - æœé£¾ï¼šå¥¹ç©¿è‘—èåˆä¸­è¯èˆ‡æ—¥ç³»é¢¨æ ¼çš„è¯éº—æœè£ï¼Œä¸Šèº«æ˜¯ç™½è‰²èˆ‡è—è‰²äº¤ç¹”çš„è¨­è¨ˆï¼Œç¹¡æœ‰é‡‘è‰²èŠ±ç´‹ï¼Œä¸‹èº«æ˜¯è—è‰²ç™¾è¤¶çŸ­è£™ï¼Œè…°é–“ç¶æœ‰å¯¬å¤§çš„è—ç´«è‰²è…°å°ï¼Œä¸Šé¢ä¹Ÿæœ‰ç²¾ç·»çš„é‡‘è‰²åœ–é¨°ã€‚è¢–å­ç‚ºå¯¬å¤§çš„å’Œé¢¨æ¨£å¼ï¼Œå¸¶æœ‰é€æ˜çš„æ·¡è—ç´—èˆ‡èŠ±æœµåœ–æ¡ˆã€‚

    - é…ä»¶ï¼šé ­ä¸Šé…æˆ´è¯éº—çš„é«®é£¾ï¼ŒåŒ…å«é‡‘è‰²é«®ç°ªèˆ‡ç´«è‰²ã€è—è‰²çš„èŠ±æœµè£é£¾ï¼Œæ­é…é‡‘è‰²è‘‰ç‰‡èˆ‡ç´…è‰²çµ²å¸¶ã€‚

    - ç¥æƒ…èˆ‡å§¿å‹¢ï¼šå¥¹çš„è¡¨æƒ…ç•¥å¸¶ç¾æ¾€æˆ–å…§æ–‚ï¼Œçœ¼ç¥æ¸…æ¾ˆï¼Œæ³¨è¦–è‘—å‰æ–¹ã€‚å¥¹ä¸€æ‰‹è‡ªç„¶å‚ä¸‹ï¼Œå¦ä¸€æ‰‹æ‰¶è‘—è…°å¸¶ï¼Œçœ‹èµ·ä¾†æŸ”ç¾è€Œæ²‰éœã€‚

    - èƒŒæ™¯ï¼šèƒŒæ™¯ç‚ºæœ¨è³ªçª—æˆ¶ï¼Œçª—å¤–æœ‰æ˜äº®çš„è‡ªç„¶å…‰ç‘å…¥ï¼Œç‡Ÿé€ å‡ºæº«æš–èˆ‡å¯§éœçš„æ°›åœã€‚

æ•´é«”ç•«é¢è‰²èª¿æŸ”å’Œï¼Œè‰²å½©æ­é…ç´°ç·»å„ªé›…ï¼Œçµ¦äººä¸€ç¨®å¤å…¸èˆ‡å¤¢å¹»èåˆçš„ç¾æ„Ÿã€‚

'''      

#chat_type1()
chat_type2()

